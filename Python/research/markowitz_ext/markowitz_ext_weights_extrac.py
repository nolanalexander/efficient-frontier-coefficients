import pandas as pdimport numpy as npimport timefrom scipy.optimize import minimize, newtonfrom sklearn.preprocessing import StandardScalerimport cvxpy as cvximport warningsimport osfrom tqdm import tqdmfrom data_processing.read_in_data import read_in_rffrom portfolio_optimization.portfolio_utils import scale_weightsfrom portfolio_optimization.markowitz import calc_tan_port_weights, calc_mean_var_weights, get_ef_coefs, correct_extreme_weights'''Extract weights from forecasted EF coefs's implied tangency portfolioMethod 1 is the best performing method:Finds the portfolio on the efficient frontier that is the minimum Euclidean distance from the forecasted tangency portfolio'''def extract_weights(test_date, ef_forecast_coefs, prior_ef_coefs_df, prior_assets_returns_df, assets_returns_df,                    prior_tan_port_weights, rf, weights_extrac_method=1,                     window=21, hyperparameter=None,                     lower_bound=None, upper_bound=None, max_leverage=1.5, max_leverage_method=None):    assets_exp_rets = prior_assets_returns_df.mean()    cov_matrix = prior_assets_returns_df.cov()    ef_coefs = prior_ef_coefs_df.loc[test_date]    # Validation    e = np.ones(len(assets_exp_rets))    ef_coefs_abc = interp_coefs_to_ABC(ef_coefs.copy())    assert np.isclose(ef_coefs_abc['A'], e.dot(np.linalg.pinv(cov_matrix)).dot(e))        hyperparameter = 100 if hyperparameter is None else hyperparameter    prior_ef_coefs = prior_ef_coefs_df.loc[test_date]        # Closest Weights to Forecasted Tan Port    if(weights_extrac_method == 1):        weights = get_min_dist_weights_to_tan_port(assets_exp_rets, cov_matrix, rf, prior_ef_coefs, ef_forecast_coefs,                                                    optimizer='SciPy', use_eq=True, on_ef=True,                                                    lower_bound=lower_bound, upper_bound=upper_bound,                                                    max_leverage=max_leverage, max_leverage_method=max_leverage_method, date=test_date)    # Least Deviation Implied Parameters    elif(weights_extrac_method == 2):        weights = get_least_deviation_implied_weights(assets_exp_rets, cov_matrix, rf, prior_ef_coefs, ef_forecast_coefs,                                                       lower_bound=lower_bound, upper_bound=upper_bound,                                                      max_leverage=max_leverage, max_leverage_method=max_leverage_method, date=test_date)    # Nearest Neighbors Historical Weights Average    elif(weights_extrac_method == 3):        weights = get_nn_weights_avg(prior_tan_port_weights, prior_ef_coefs_df, ef_forecast_coefs, hyperparameter,                                      lower_bound=lower_bound, upper_bound=upper_bound, max_leverage=max_leverage)    # Nearest Neighbors Historical Parameter Average    elif(weights_extrac_method == 4):        weights = get_nn_param_avg(assets_returns_df, rf, prior_ef_coefs_df, ef_forecast_coefs, hyperparameter, window,                                    lower_bound=lower_bound, upper_bound=upper_bound, max_leverage=max_leverage, max_leverage_method=max_leverage_method,                                   date=test_date)    else:        raise ValueError('Method', weights_extrac_method, 'is not a valid weights extraction method')            return weightsdef extract_all_weights(assets_set, subfolder_name, lookback_method, test_start_date,                        weights_extrac_method=1, window=21, hyperparameter=None,                        lower_bound=None, upper_bound=None,                        max_leverage=1.5, max_leverage_method=None, smooth_forecasts=False):    start_time = time.time()    lookback_method = lookback_method.lower()    me_dir = '../Portfolios/'+assets_set+'/Markowitz_Ext/'    ef_forecast_coefs_df = pd.read_csv(me_dir+'forecasted_EF_coefs_'+lookback_method+'.csv', index_col=0, parse_dates=True)    if smooth_forecasts:        ef_forecast_coefs_df = ef_forecast_coefs_df.ewm(halflife=10).mean()    ef_coefs_df = pd.read_csv('../Portfolios/'+assets_set+'/EF_Coefs/EF_coefs_'+lookback_method+'.csv', index_col=0, parse_dates=True)[['r_MVP', 'sigma_MVP', 'u']]    assets_returns_df = pd.read_csv('../Portfolios/'+assets_set+'/Assets_Data/assets_returns_data.csv', index_col=0, parse_dates=True)    tan_port_weights = pd.read_csv('../Portfolios/'+assets_set+'/Versions/'+subfolder_name+'/Weights/daily_weights_tan_'+lookback_method+'.csv', index_col=0, parse_dates=True)    rfs = read_in_rf(assets_returns_df.index)        test_dates = ef_forecast_coefs_df.index[ef_forecast_coefs_df.index >= test_start_date]    mark_ext_weights_df = pd.DataFrame(columns=assets_returns_df.columns)    prior_ef_coefs_df = ef_coefs_df.loc[ef_coefs_df.index < test_start_date].copy()    prior_assets_returns_df = assets_returns_df.loc[assets_returns_df.index < test_start_date].iloc[-window:].copy()    prior_tan_port_weights = tan_port_weights.loc[tan_port_weights.index < test_start_date].copy()        p_bar = tqdm(test_dates)    for test_date in p_bar:        p_bar.set_description(f'{pd.to_datetime(test_date).date()} ')        prior_ef_coefs_df.loc[test_date] = ef_coefs_df.loc[test_date].copy()        prior_assets_returns_df.loc[test_date] = assets_returns_df.loc[test_date].copy()        prior_assets_returns_df = prior_assets_returns_df.iloc[-window:]        prior_tan_port_weights.loc[test_date] = tan_port_weights.loc[test_date].copy()        ef_forecast_coefs = ef_forecast_coefs_df.loc[test_date]        rf = rfs.loc[test_date].copy()        cur_mark_ext_weights = extract_weights(test_date, ef_forecast_coefs, prior_ef_coefs_df, prior_assets_returns_df,                                                 assets_returns_df, prior_tan_port_weights, rf, weights_extrac_method=weights_extrac_method,                                                 window=window, hyperparameter=hyperparameter, lower_bound=lower_bound, upper_bound=upper_bound,                                                max_leverage=max_leverage, max_leverage_method=max_leverage_method)        mark_ext_weights_df.loc[test_date] = cur_mark_ext_weights        weights_dir = '../Portfolios/'+assets_set+'/Versions/'+subfolder_name+'/Weights/'    me_weights_dir = weights_dir +'Markowitz_Ext/'    if not os.path.exists(me_weights_dir):        os.makedirs(me_weights_dir)    mark_ext_weights_df.to_csv(me_weights_dir + 'daily_weights_mark_ext_'+lookback_method+'.csv')    print('Weights extraction runtime: ' + str(round((time.time() - start_time)/60, 1)) + ' mins')    return mark_ext_weights_dfdef interp_coefs_to_ABC(interp_coefs):    return pd.Series([1/interp_coefs[1]**2, interp_coefs[0]/interp_coefs[1]**2,                       interp_coefs[2]**2 + interp_coefs[0]**2/interp_coefs[1]**2],                      index=['A', 'B', 'C'])def get_euclidean_dist(x1, x2):    return np.sqrt(sum((x1-x2)**2))def get_euclidean_dist_of_coefs(ef_forecast_coefs, prior_ef_coefs_df):    scaler = StandardScaler().fit(prior_ef_coefs_df)    prior_ef_coefs_df_scaled = pd.DataFrame(scaler.transform(prior_ef_coefs_df),                                             index=prior_ef_coefs_df.index, columns=prior_ef_coefs_df.columns)    ef_forecast_coefs_scaled = scaler.transform(ef_forecast_coefs.values.reshape(1, -1))[0]    euclidean_dists = prior_ef_coefs_df_scaled.apply(get_euclidean_dist, axis=1, x2=ef_forecast_coefs_scaled )    euclidean_dists = euclidean_dists.sort_values(ascending=True)    return euclidean_distsdef get_min_dist_weights_to_tan_port(assets_exp_rets, cov_matrix, rf, prior_ef_coefs, ef_forecast_coefs, use_eq=True, on_ef=True,                                      optimizer='SciPy', lower_bound=None, upper_bound=None, max_leverage=1.5, max_leverage_method=None, date=None):    # A_hat, B_hat, C_hat = interp_coefs_to_ABC(ef_forecast_coefs.copy())    # A, B, C = interp_coefs_to_ABC(prior_ef_coefs)    r_mvp, sigma_mvp, u = prior_ef_coefs    r_mvp_hat, sigma_mvp_hat, u_hat = ef_forecast_coefs    # r_mvp_hat = np.mean([r_mvp_hat, r_mvp])    # sigma_mvp_hat = np.mean([sigma_mvp_hat, sigma_mvp])    # u_hat = np.mean([u_hat, u])        # forecasted_tan_port_ret_ = (C_hat - B_hat * rf)/(B_hat - A_hat * rf)    # forecasted_tan_port_sd_ = np.sqrt((A_hat * forecasted_tan_port_ret_**2 - 2 * B_hat * forecasted_tan_port_ret_ + C_hat)/(A_hat * C_hat - B_hat**2))        forecasted_tan_port_ret = (r_mvp_hat**2 + u_hat**2 * sigma_mvp_hat**2 - r_mvp_hat * rf) / (r_mvp_hat - rf)    forecasted_tan_port_sd = np.sqrt( (u_hat**-1 * (forecasted_tan_port_ret - r_mvp_hat))**2 + sigma_mvp_hat**2)        # def get_ef_sigma(r):    #     return np.sqrt((A * r**2 - 2 * B * r + C) / max((A * C - B**2), 1e-20))    def get_ef_sigma(r):        return np.sqrt((1/max(u, 1e-20) * (r - r_mvp))**2 + sigma_mvp**2)        def deriv_dist(r, r_hat, r_MVP, sigma_MVP, u):        return 2*(r - r_hat) + (u**-2*(r - r_MVP))/np.sqrt(u**-2*(r - r_MVP)**2 + sigma_MVP**2)        # Equation    def distance_to_tan_port_eq(r):        return get_euclidean_dist(np.array([r[0], get_ef_sigma(r[0])]), np.array([forecasted_tan_port_ret, forecasted_tan_port_sd]))    # Emperical    def distance_to_tan_port_emp(r):        weights_r = calc_mean_var_weights(r[0], assets_exp_rets, cov_matrix,                                           lower_bound=None, upper_bound=None,                                           max_leverage=None, max_leverage_method=None, optimizer='SciPy')        sigma = weights_r.T.dot(cov_matrix).dot(weights_r) if weights_r is not None else 1e4        return get_euclidean_dist(np.array([r[0], sigma]), np.array([forecasted_tan_port_ret, forecasted_tan_port_sd]))    distance_to_tan_port = distance_to_tan_port_eq if use_eq else distance_to_tan_port_emp    max_leverage_method = 'scaling' if max_leverage_method is not None else None        # The minimum distance portfolio must be on the efficient frontier    if on_ef:        A, B, C = get_ef_coefs(assets_exp_rets, cov_matrix)        r_MVP = B/A                if optimizer == 'CVXPY':            r = cvx.Variable(1)            distance_to_tan_port_val = distance_to_tan_port(r)            cons = [r >= r_MVP]            prob = cvx.Problem(cvx.Minimize(distance_to_tan_port_val), cons)            prob.solve(solver='OSQP', eps_abs=1e-10, eps_rel=1e-10, eps_prim_inf=1e-15, eps_dual_inf=1e-15, max_iter=10000)            # Attempts 5 warm runs if not optimal            solve_attempts = 1            while prob.status != 'optimal' and solve_attempts < 5:                prob.solve(solver='OSQP', eps_abs=1e-10, eps_rel=1e-10, eps_prim_inf=1e-15, eps_dual_inf=1e-15, max_iter=10000)                solve_attempts += 1            min_dist_port_ret = r.value if prob.status == 'optimal' else None            if min_dist_port_ret is None:                prob = cvx.Problem(cvx.Minimize(distance_to_tan_port_val), cons)                prob.solve(solver='OSQP', eps_abs=1e-10, eps_rel=1e-10, eps_prim_inf=1e-15, eps_dual_inf=1e-15, max_iter=10000, verbose=True)                optimizer = 'SciPy'                print(f'RuntimeWarning: In M-E, CVXPY solver failed on {date.date() if date is not None else date}. Defaulting to SciPy solver.')                if optimizer == 'SciPy':            min_dist_port_ret = r_MVP            bounds = ((r_MVP, None),) # only on upper half of efficient frontier            optimization = minimize(distance_to_tan_port, min_dist_port_ret, method='SLSQP' ,                                    bounds=bounds, options = {'disp':False, 'ftol': 1e-12, 'maxiter': 1e5} ,                                    constraints=[])            if(not optimization.success):                print(optimization)            min_dist_port_ret = optimization.x[0]                    elif optimizer not in ['CVXPY', 'SciPy']:            raise ValueError('Invalid optimizer:', optimizer)                    weights = calc_mean_var_weights(min_dist_port_ret, assets_exp_rets, cov_matrix,                                         lower_bound=lower_bound, upper_bound=upper_bound,                                         max_leverage=max_leverage, max_leverage_method=max_leverage_method,                                        date=date)        # The minimum distance portfolio does not have to be on the efficient frontier    else:        if optimizer == 'CVXPY':            w = cvx.Variable(len(assets_exp_rets.index))            distance_to_tan_port_val = distance_to_tan_port([w @ assets_exp_rets])            cons = [cvx.sum(w) == 1]            prob = cvx.Problem(cvx.Minimize(distance_to_tan_port_val), cons)            try:                with warnings.catch_warnings():                    warnings.simplefilter("ignore")                    prob.solve(solver='OSQP', eps_abs=1e-10, eps_rel=1e-10, eps_prim_inf=1e-15, eps_dual_inf=1e-15, max_iter=10000)                    # Attempts 5 warm runs if not optimal                    solve_attempts = 1                    while prob.status != 'optimal' and solve_attempts < 5:                        prob.solve(solver='OSQP', eps_abs=1e-10, eps_rel=1e-10, eps_prim_inf=1e-15, eps_dual_inf=1e-15, max_iter=10000)                        solve_attempts += 1                    staus = prob.status             except:                if max_leverage_method == 'scaling':                    print(f'RuntimeWarning: In M-V, CVXPY reached max_iter on {date.date() if date is not None else date} with max_leverage_method \'{max_leverage_method}\'')                weights = None                status = 'failure'            weights = w.value if status == 'optimal' else None            if weights is None:                prob = cvx.Problem(cvx.Minimize(distance_to_tan_port_val), cons)                prob.solve(solver='OSQP', eps_abs=1e-10, eps_rel=1e-10, eps_prim_inf=1e-15, eps_dual_inf=1e-15, max_iter=10000, verbose=True)                optimizer = 'SciPy'                print(f'RuntimeWarning: In M-E, CVXPY solver failed on {date.date() if date is not None else date}. Defaulting to SciPy solver.')                if optimizer == 'SciPy':            num_assets = len(assets_exp_rets)            weights = np.repeat(1/num_assets, num_assets)            cons = [{'type': 'eq', 'fun': lambda x: sum(x) - 1}]            bounds = ((None, None),)*num_assets                        def weights_distance_to_tan_port(weights):                return distance_to_tan_port([weights @ assets_exp_rets])                        optimization = minimize(weights_distance_to_tan_port, weights, method='SLSQP', bounds=bounds,                                     options = {'disp':False, 'ftol': 1e-15, 'maxiter': 1e5} , constraints=cons)            weights = optimization.x            if not optimization.success:                # print(optimization)                print(f'RuntimeWarning: Min Dist Portfolio not on EF did not converge on {date.date() if date is not None else date}. Defaulting to tangency portfolio.')                weights = calc_tan_port_weights(assets_exp_rets, cov_matrix, rf, lower_bound=lower_bound, upper_bound=upper_bound,                                                 max_leverage=max_leverage, max_leverage_method=max_leverage_method, date=date)        elif optimizer not in ['CVXPY', 'SciPy']:            raise ValueError('Invalid optimizer:', optimizer)        weights = correct_extreme_weights(weights, assets_exp_rets=assets_exp_rets, cov_matrix=cov_matrix,                                           max_leverage=max_leverage, max_leverage_method=max_leverage_method, date=date)    return weights        def get_least_deviation_implied_weights(assets_exp_rets, cov_matrix, rf, prior_ef_coefs, ef_forecast_coefs,                                         lower_bound=None, upper_bound=None, max_leverage=1.5, max_leverage_method=None, date=None):    A_hat, B_hat, C_hat = interp_coefs_to_ABC(ef_forecast_coefs.copy())    A, B, C = interp_coefs_to_ABC(prior_ef_coefs)    e = np.ones(len(assets_exp_rets))    def abs_deviation_to_means(x):        return sum(np.abs(x - assets_exp_rets)) * 1000    def sq_deviation_to_means(x):        return sum((x - assets_exp_rets)**2) * 1000    def print_callback(x):        print(x)    means_est = assets_exp_rets.copy()    cov_mat_est = np.linalg.pinv( (np.linalg.pinv(cov_matrix) * A_hat/ A_hat) )    inv_cov_mat_est = np.linalg.pinv(cov_mat_est)    cons = [{'type': 'eq', 'fun': lambda x: x.dot(inv_cov_mat_est).dot(e.T) - B_hat }]    cons.append({'type':'eq', 'fun': lambda x: x.dot(inv_cov_mat_est).dot(x.T) - C_hat })    bounds = ((-1.0, 1.0),)*len(means_est)    optimization = minimize(sq_deviation_to_means, means_est, method='SLSQP' ,                            bounds=bounds, options = {'disp':False, 'ftol': 1e-6, 'maxiter': 1e5} ,                            constraints=cons)    means_est = optimization.x    if not optimization.success:        print(optimization)        means_est = assets_exp_rets    weights = calc_tan_port_weights(means_est, cov_mat_est, rf,                                    lower_bound=lower_bound, upper_bound=upper_bound,                                     max_leverage=max_leverage, max_leverage_method=max_leverage_method, date=date)    return weights    def get_nn_weights_avg(prior_tan_port_weights, prior_ef_coefs_df, ef_forecast_coefs, hyperparameter, max_leverage=1.5):    euclidean_dists = get_euclidean_dist_of_coefs(ef_forecast_coefs, prior_ef_coefs_df)    weights = prior_tan_port_weights.loc[euclidean_dists.index[:hyperparameter]].mean()    weights[weights > 0] = weights[weights > 0] * (-sum(weights[weights < 0]) + 1) / sum(weights[weights > 0]) # scale weights to sum to 1    weights = scale_weights(weights, max_leverage)    return weightsdef get_nn_param_avg(assets_returns_df, rf, prior_ef_coefs_df, ef_forecast_coefs, hyperparameter, window,                      lower_bound=None, upper_bound=None, max_leverage=1.5, max_leverage_method=None, date=None):    means_vecs, cov_mats = [], []    euclidean_dists = get_euclidean_dist_of_coefs(ef_forecast_coefs, prior_ef_coefs_df)    for date in euclidean_dists.index[:hyperparameter]:        nn_prior_assets_returns_df = assets_returns_df.loc[assets_returns_df.index <= date].iloc[-window:]        means_vecs = means_vecs + [nn_prior_assets_returns_df.mean()]        cov_mats = cov_mats + [nn_prior_assets_returns_df.cov()]    # print(np.array(means_vecs))    avg_means = np.array(means_vecs).mean(0)    avg_cov_mat = np.array(cov_mats).mean(0)/hyperparameter    weights = calc_tan_port_weights(avg_means, avg_cov_mat, rf, lower_bound=lower_bound, upper_bound=upper_bound,                                     max_leverage=max_leverage, max_leverage_method=max_leverage_method, date=date)    return weights    