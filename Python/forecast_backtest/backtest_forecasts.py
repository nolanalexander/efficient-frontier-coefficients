import numpy as npimport pandas as pdimport timeimport cvxpy as cvximport warningsfrom data_processing.data_cleaning import multiindex_df_along_one_colfrom data_processing.read_in_data import read_in_spxtrfrom portfolio_optimization.portfolio_utils import scale_weights, calc_portfolio_metricsfrom portfolio_optimization.simulate_portfolios import get_portfolio_vals, plot_portfolios'''Given forecasts of assets on test dates, backtests a strategy dependent on the data type (continuous or binary).'''# Finds the weights that maximize expected returndef backtest_continuous(forecast_df, long_short=False, max_leverage=1.5, lower_bound=None, upper_bound=None, abs_lower_bound=None):    weights_df = pd.DataFrame(columns=forecast_df.columns, index=forecast_df.index)    for date in forecast_df.index:        forecasts = forecast_df.loc[date].values        w = cvx.Variable(len(forecasts))        er = w @ forecasts                cons = [cvx.sum(w) == (1 if not long_short else 0)]        if max_leverage is not None:            cons += [cvx.norm(w, 1) <= max_leverage]        cons += [w >= lower_bound] if lower_bound is not None else [w >= -100]        cons += [w <= upper_bound] if upper_bound is not None else [w <= 100]        if abs_lower_bound is not None:            cons += [w >= abs_lower_bound]            cons += [w <= abs_lower_bound]        prob = cvx.Problem(cvx.Maximize(er), cons)        try:            with warnings.catch_warnings():                warnings.simplefilter("ignore")                prob.solve(solver='OSQP', eps_abs=1e-10, eps_rel=1e-10, eps_prim_inf=1e-15, eps_dual_inf=1e-15, max_iter=10000)                # Attempts 5 warm runs if not optimal                solve_attempts = 1                while prob.status != 'optimal' and solve_attempts < 5:                    prob.solve(solver='OSQP', eps_abs=1e-10, eps_rel=1e-10, eps_prim_inf=1e-15, eps_dual_inf=1e-15, max_iter=10000)                    solve_attempts += 1                weights = w.value if prob.status == 'optimal' else None                status = prob.status        except:            raise ValueError(f'Solver reached max_iter on {date}')        if status != 'optimal':            raise ValueError(f'Solver failed to converge on {date}')                    weights_df.loc[date] = weights    return weights_dfdef make_weights_long_short(weights):    if len(weights[weights < 0]) == 0:        weights -= np.mean(weights)    elif len(weights[weights > 0]) == 0:        weights += np.mean(weights)    return weights# Weights by probabilistic forecast of being up/downdef backtest_binary(forecast_df, discrete_prediction=False, long_short=False, max_leverage=1.5, lower_bound=None, upper_bound=None, abs_lower_bound=None):    if discrete_prediction:        weights_df = forecast_df.applymap(lambda x : 1 if x == 'Up' else -1)    else:        weights_df = 2 * (forecast_df - 0.5)            if long_short:        weights_df = weights_df.apply(make_weights_long_short, axis=1)            weights_df = weights_df.apply(scale_weights, axis=1, max_leverage=max_leverage, force_rescale=True, long_short=long_short)    if lower_bound is not None:        weights_df[weights_df < lower_bound] = lower_bound    if upper_bound is not None:        weights_df[weights_df > upper_bound] = upper_bound    if abs_lower_bound is not None:         weights_df[((weights_df > 0) & (weights_df < abs_lower_bound)) | ((weights_df < 0) & (weights_df > -abs_lower_bound))] = 0    if lower_bound is not None or upper_bound is not None or abs_lower_bound is not None:        weights_df = weights_df.apply(scale_weights, axis=1, max_leverage=max_leverage, force_rescale=True, long_short=long_short)    return weights_df# Backtests the appropriate data type strategydef backtest_forecasts(multiindex_forecast_df, is_continuous, long_short=False, max_leverage=1.5, discrete_prediction=False):    forecast_col_name = 'Forecast' if is_continuous or not discrete_prediction else 'Discrete_Forecast'    forecast_df = multiindex_df_along_one_col(multiindex_forecast_df.copy(), forecast_col_name)    if is_continuous:        weights_df = backtest_continuous(forecast_df, long_short=long_short, max_leverage=max_leverage)    else:        weights_df = backtest_binary(forecast_df, discrete_prediction=discrete_prediction, long_short=long_short, max_leverage=max_leverage)    return weights_df# Runs the full backtest processdef run_backtest_forecasts(assets_set, predictand_name, forecast_model, version_name, is_continuous,                            long_short=False, max_leverage=1.5, discrete_prediction=False, transaction_cost=0.01):    start_time = time.time()    forecast_backtest_dir = '../Portfolios/'+assets_set+'/Forecast_Backtest/' + predictand_name + '/' + version_name + '/'    forecast_df = pd.read_csv(forecast_backtest_dir + predictand_name.lower() + '_forecast_df.csv', index_col=['Date', 'Ticker'], parse_dates=True)    forecast_df = forecast_df.sort_values(['Date', 'Ticker'])    weights_df = backtest_forecasts(forecast_df, is_continuous, long_short=long_short, max_leverage=max_leverage, discrete_prediction=discrete_prediction)    weights_df.to_csv(forecast_backtest_dir + 'backtest_weights.csv')        test_start_date = forecast_df.index.get_level_values('Date')[0]    assets_returns_df = pd.read_csv('../Portfolios/'+assets_set+'/Assets_Data/assets_returns_data.csv', index_col=0, parse_dates=True)    assets_returns_df = assets_returns_df.sort_index()    test_assets_returns_df = assets_returns_df.loc[assets_returns_df.index >= test_start_date]        spx_df = read_in_spxtr(assets_set, weights_df.index)    spx_weights_df = pd.DataFrame({'^SP500TR' : np.repeat(1,len(spx_df.index))}, index=spx_df.index)    spx_returns_df = spx_df[['Chg']].rename(columns={'Chg' : '^SP500TR'})        eq_weights_df = pd.DataFrame(1/len(weights_df.columns), columns=weights_df.columns, index=weights_df.index)        port_vals_df = pd.DataFrame({'Backtest'   : get_portfolio_vals(weights_df, test_assets_returns_df, transaction_cost=0.01)['Port_Vals'],                                 '^SP500TR'   : get_portfolio_vals(spx_weights_df, spx_returns_df)['Port_Vals'],                                 'Eq_Weights' : get_portfolio_vals(eq_weights_df, test_assets_returns_df)['Port_Vals'] })    label_by_port = {'Backtest'   : 'Backtest',                     '^SP500TR'   : 'S&P 500',                     'Eq_Weights' : 'Equal Weights'}    plot_portfolios(port_vals_df, label_by_port, 'Backtest Against Baselines',                     forecast_backtest_dir, 'backtest_vs_baselines.png', scale='percent')    metrics_df = port_vals_df.apply(calc_portfolio_metrics).T    metrics_df.to_csv(forecast_backtest_dir + 'backtest_metrics.csv')        print('Backtest Forecasts Runtime:', round((time.time() - start_time)/60), 'mins')            